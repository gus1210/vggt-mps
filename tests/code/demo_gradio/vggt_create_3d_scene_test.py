"""
Tests for vggt_create_3d_scene in demo_gradio.py that reproduce the tutorial exactly.

Tutorial: VGGT_Agent/notebooks/demo_gradio/demo_gradio_execution_final.ipynb
"""

from __future__ import annotations
import pathlib
import pytest
import sys
from fastmcp import Client
import os
import pandas as pd
import numpy as np
import shutil
from PIL import Image
import imagehash

# Add project root to Python path to enable src imports
project_root = pathlib.Path(__file__).parent.parent.parent.parent
sys.path.insert(0, str(project_root))

# ========= Fixtures =========
@pytest.fixture
def server(test_directories):
    """FastMCP server fixture with the demo_gradio tool."""
    # Force module reload
    module_name = 'src.tools.demo_gradio'
    if module_name in sys.modules:
        del sys.modules[module_name]

    import src.tools.demo_gradio
    return src.tools.demo_gradio.demo_gradio_mcp

@pytest.fixture
def test_directories():
    """Setup test directories and environment variables."""
    test_input_dir = pathlib.Path(__file__).parent.parent.parent / "data" / "demo_gradio"
    test_output_dir = pathlib.Path(__file__).parent.parent.parent / "results" / "demo_gradio"

    test_input_dir.mkdir(parents=True, exist_ok=True)
    test_output_dir.mkdir(parents=True, exist_ok=True)

    # Environment variable management
    old_input_dir = os.environ.get("DEMO_GRADIO_INPUT_DIR")
    old_output_dir = os.environ.get("DEMO_GRADIO_OUTPUT_DIR")

    os.environ["DEMO_GRADIO_INPUT_DIR"] = str(test_input_dir.resolve())
    os.environ["DEMO_GRADIO_OUTPUT_DIR"] = str(test_output_dir.resolve())

    yield {"input_dir": test_input_dir, "output_dir": test_output_dir}

    # Cleanup
    if old_input_dir is not None:
        os.environ["DEMO_GRADIO_INPUT_DIR"] = old_input_dir
    else:
        os.environ.pop("DEMO_GRADIO_INPUT_DIR", None)

    if old_output_dir is not None:
        os.environ["DEMO_GRADIO_OUTPUT_DIR"] = old_output_dir
    else:
        os.environ.pop("DEMO_GRADIO_OUTPUT_DIR", None)

# ========= Input Fixtures (Tutorial Values) =========
@pytest.fixture
def vggt_create_3d_scene_inputs(test_directories) -> dict:
    """Use NPZ predictions file generated by previous tool for sequential testing."""
    # Look for existing NPZ predictions file from previous tool's test
    # This implements the sequential dependency where Tool 3 uses Tool 2's output
    predictions_files = list(test_directories["output_dir"].glob("**/predictions.npz"))

    if not predictions_files:
        # If no previous test output, create a minimal NPZ file for testing
        # This uses tutorial-like data structure
        test_predictions_path = test_directories["input_dir"] / "test_predictions.npz"

        # Create minimal prediction data matching tutorial structure
        dummy_predictions = {
            'pose_enc': np.random.randn(1, 8, 80),  # Tutorial showed pose encoding
            'depth': np.random.rand(8, 518, 518, 1),  # Tutorial showed depth maps
            'depth_conf': np.random.rand(8, 518, 518),  # Tutorial showed confidence maps
            'world_points': np.random.randn(8, 518, 518, 3),  # Tutorial showed 3D points
            'world_points_conf': np.random.rand(8, 518, 518),  # Tutorial showed point confidence
            'images': np.random.rand(8, 518, 518, 3),  # Tutorial showed input images
            'extrinsic': np.random.randn(8, 3, 4),  # Tutorial showed camera extrinsics
            'intrinsic': np.random.randn(8, 3, 3),  # Tutorial showed camera intrinsics
            'world_points_from_depth': np.random.randn(8, 518, 518, 3),  # Tutorial implementation
        }

        np.savez(str(test_predictions_path), **dummy_predictions)
        predictions_path = str(test_predictions_path)
    else:
        # Use the actual predictions file from Tool 2's test
        predictions_path = str(predictions_files[0])

    return {
        "predictions_path": predictions_path,
        "conf_thres": 50.0,  # Tutorial default
        "frame_filter": "All",  # Tutorial default
        "mask_black_bg": False,  # Tutorial default
        "mask_white_bg": False,  # Tutorial default
        "show_cam": True,  # Tutorial default
        "mask_sky": False,  # Tutorial default
        "prediction_mode": "Depthmap and Camera Branch",  # Tutorial default
        "out_prefix": "test_vggt_3d_scene"
    }

# ========= Tests (Mirror Tutorial Only) =========
@pytest.mark.asyncio
async def test_vggt_create_3d_scene(server, vggt_create_3d_scene_inputs, test_directories):
    async with Client(server) as client:
        result = await client.call_tool("vggt_create_3d_scene", vggt_create_3d_scene_inputs)
        result_data = result.data

        # 1. File Output Verification (tutorial creates GLB file and scene summary)
        artifacts = result_data.get("artifacts", [])

        # Check required files exist
        glb_file_found = False
        summary_file_found = False

        for artifact in artifacts:
            artifact_path = pathlib.Path(artifact["path"])
            if artifact["description"] == "3D scene GLB file":
                glb_file_found = artifact_path.exists()
                assert glb_file_found, f"GLB file not found: {artifact_path}"
                # Verify it's actually a GLB file
                assert artifact_path.suffix == '.glb', f"Expected .glb file, got: {artifact_path.suffix}"
            elif artifact["description"] == "Scene creation summary":
                summary_file_found = artifact_path.exists()
                assert summary_file_found, f"Summary file not found: {artifact_path}"

        assert glb_file_found, "3D scene GLB file not found in artifacts"
        assert summary_file_found, "Scene creation summary file not found in artifacts"

        # 2. GLB File Verification
        glb_file_path = None
        for artifact in artifacts:
            if artifact["description"] == "3D scene GLB file":
                glb_file_path = pathlib.Path(artifact["path"])
                break

        assert glb_file_path is not None, "Could not find GLB file path"

        # Check GLB file is not empty and has reasonable size
        glb_size = glb_file_path.stat().st_size
        assert glb_size > 0, "GLB file should not be empty"
        assert glb_size > 1000, f"GLB file seems too small: {glb_size} bytes"  # Reasonable minimum size

        # 3. Scene Summary Verification
        summary_file_path = None
        for artifact in artifacts:
            if artifact["description"] == "Scene creation summary":
                summary_file_path = pathlib.Path(artifact["path"])
                break

        summary_df = pd.read_csv(summary_file_path)
        expected_columns = ['confidence_threshold', 'frame_filter', 'mask_black_bg',
                           'mask_white_bg', 'show_cam', 'mask_sky', 'prediction_mode',
                           'glb_file', 'creation_timestamp']
        actual_columns = summary_df.columns.tolist()
        assert all(col in actual_columns for col in expected_columns), f"Missing expected columns: {set(expected_columns) - set(actual_columns)}"

        # 4. Specific Output Value Verification (from tutorial defaults)
        # Tutorial used default values: conf_thres=50.0, frame_filter="All", etc.
        conf_thres = summary_df.iloc[0]['confidence_threshold']
        assert conf_thres == 50.0, f"Expected confidence threshold 50.0 (tutorial default), got {conf_thres}"

        frame_filter = summary_df.iloc[0]['frame_filter']
        assert frame_filter == "All", f"Expected frame filter 'All' (tutorial default), got {frame_filter}"

        mask_black_bg = summary_df.iloc[0]['mask_black_bg']
        assert mask_black_bg == False, f"Expected mask_black_bg False (tutorial default), got {mask_black_bg}"

        mask_white_bg = summary_df.iloc[0]['mask_white_bg']
        assert mask_white_bg == False, f"Expected mask_white_bg False (tutorial default), got {mask_white_bg}"

        show_cam = summary_df.iloc[0]['show_cam']
        assert show_cam == True, f"Expected show_cam True (tutorial default), got {show_cam}"

        mask_sky = summary_df.iloc[0]['mask_sky']
        assert mask_sky == False, f"Expected mask_sky False (tutorial default), got {mask_sky}"

        prediction_mode = summary_df.iloc[0]['prediction_mode']
        assert prediction_mode == "Depthmap and Camera Branch", f"Expected 'Depthmap and Camera Branch' (tutorial default), got {prediction_mode}"

        # 5. Message verification
        expected_message = "3D scene created successfully"
        assert result_data.get("message", "") == expected_message, f"Expected message '{expected_message}', got: {result_data.get('message', '')}"

        # 6. GLB filename verification (based on tutorial logic)
        # Tutorial generates filename with parameters: glbscene_{conf_thres}_{frame_filter}_maskb{mask_black_bg}_maskw{mask_white_bg}_cam{show_cam}_sky{mask_sky}_pred{prediction_mode}.glb
        expected_filename_parts = [
            "glbscene",
            "50.0",  # conf_thres
            "All",   # frame_filter
            "maskbFalse",  # mask_black_bg
            "maskwFalse",  # mask_white_bg
            "camTrue",     # show_cam
            "skyFalse",    # mask_sky
            "predDepthmap_and_Camera_Branch"  # prediction_mode with spaces replaced
        ]

        glb_filename = glb_file_path.name
        for part in expected_filename_parts:
            assert part in glb_filename, f"Expected filename part '{part}' not found in GLB filename: {glb_filename}"

        # 7. Image Verification (tutorial doesn't show specific GLB visualization, skip detailed image comparison)
        # The tutorial focused on the GLB file creation rather than specific visual outputs
        pass